{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjo9XlejnJCn"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "taI6OSXMnJCv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "import argparse\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fpKUraZnJC0",
        "outputId": "f8d03564-6515-46ee-9208-0c7ae82a0b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this is the image shape  (1, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Adjust sys.argv to remove unwanted Jupyter arguments\n",
        "sys.argv = sys.argv[:1]  # Keep only the script name, remove Jupyter's arguments\n",
        "\n",
        "# Now proceed with argparse as usual\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=200, help=\"size of the batches\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of CPU threads for data loading\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=2000, help=\"interval between image sampling\")\n",
        "\n",
        "# Parse the arguments\n",
        "opt = parser.parse_args()\n",
        "\n",
        "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
        "print(\"this is the image shape \", img_shape)\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sxM1bS38nJC4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Data Loading Classes and Functions\n",
        "class NumpyDataset(Dataset):\n",
        "    def __init__(self, dataX, dataY=None):\n",
        "        self.dataX = np.load(dataX)\n",
        "        self.dataY = np.load(dataY) if dataY is not None else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataX)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.tensor(self.dataX[idx], dtype=torch.float32)\n",
        "        label = (\n",
        "            torch.tensor(self.dataY[idx], dtype=torch.long)\n",
        "            if self.dataY is not None\n",
        "            else None\n",
        "        )\n",
        "        return data, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW2XZOOOnJC5",
        "outputId": "b77088b3-b5b3-42fe-c5ed-531f7ac659d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and processing MNIST dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.57MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 133kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.08MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.58MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Define file paths\n",
        "# dataX = \"../../../data/mnist/trainX.npy\"\n",
        "# dataY = \"../../../data/mnist/trainY.npy\"\n",
        "# devX = \"../../../data/mnist/validX.npy\"\n",
        "# devY = \"../../../data/mnist/validY.npy\"\n",
        "# testX = \"../../../data/mnist/testX.npy\"\n",
        "# testY = \"../../../data/mnist/testY.npy\"\n",
        "\n",
        "# # Create dataloaders\n",
        "# train_dataset = NumpyDataset(dataX, dataY)\n",
        "# train_loader = DataLoader(dataset=train_dataset, batch_size=200, shuffle=True)\n",
        "\n",
        "# dev_dataset = NumpyDataset(devX, devY)\n",
        "# dev_loader = DataLoader(dataset=dev_dataset, batch_size=200, shuffle=False)\n",
        "\n",
        "# test_dataset = NumpyDataset(testX, testY)\n",
        "# test_loader = DataLoader(dataset=test_dataset, batch_size=200, shuffle=False)\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# Assuming NumpyDataset is a custom class you have defined\n",
        "# Define file paths\n",
        "base_dir = \"../../../data/mnist/\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "dataX = os.path.join(base_dir, \"trainX.npy\")\n",
        "dataY = os.path.join(base_dir, \"trainY.npy\")\n",
        "devX = os.path.join(base_dir, \"validX.npy\")\n",
        "devY = os.path.join(base_dir, \"validY.npy\")\n",
        "testX = os.path.join(base_dir, \"testX.npy\")\n",
        "testY = os.path.join(base_dir, \"testY.npy\")\n",
        "\n",
        "# Check if any MNIST files are missing\n",
        "required_files = [dataX, dataY, devX, devY, testX, testY]\n",
        "if not all(os.path.exists(f) for f in required_files):\n",
        "    print(\"Downloading and processing MNIST dataset...\")\n",
        "\n",
        "    # Download raw MNIST data\n",
        "    train_set = torchvision.datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True\n",
        "    )\n",
        "    test_set = torchvision.datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True\n",
        "    )\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    train_images = train_set.data.numpy()\n",
        "    train_labels = train_set.targets.numpy()\n",
        "    test_images = test_set.data.numpy()\n",
        "    test_labels = test_set.targets.numpy()\n",
        "\n",
        "    # Shuffle training data\n",
        "    shuffle_idx = np.random.permutation(len(train_images))\n",
        "    train_images = train_images[shuffle_idx]\n",
        "    train_labels = train_labels[shuffle_idx]\n",
        "\n",
        "    # Split train into train/validation (50k/10k)\n",
        "    train_images = train_images.astype(np.float32) / 255.0\n",
        "    train_labels = train_labels.astype(np.int64)\n",
        "\n",
        "    # Save processed data\n",
        "    np.save(dataX, train_images[:50000])\n",
        "    np.save(dataY, train_labels[:50000])\n",
        "    np.save(devX, train_images[50000:])\n",
        "    np.save(devY, train_labels[50000:])\n",
        "\n",
        "    # Process and save test data\n",
        "    test_images = test_images.astype(np.float32) / 255.0\n",
        "    test_labels = test_labels.astype(np.int64)\n",
        "    np.save(testX, test_images)\n",
        "    np.save(testY, test_labels)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataset = NumpyDataset(dataX, dataY)\n",
        "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
        "\n",
        "dev_dataset = NumpyDataset(devX, devY)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=200, shuffle=False)\n",
        "\n",
        "test_dataset = NumpyDataset(testX, testY)\n",
        "test_loader = DataLoader(test_dataset, batch_size=200, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YcCwXMHMnJC6"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.mu_layer = nn.Linear(hidden_dims[1], latent_dim)\n",
        "        self.logvar_layer = nn.Linear(hidden_dims[1], latent_dim)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self, sigma=0.05):\n",
        "        for layer in [*self.model, self.mu_layer, self.logvar_layer]:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
        "                nn.init.constant_(layer.bias, 0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        h = self.model(x)\n",
        "        mu = self.mu_layer(h)\n",
        "        logvar = self.logvar_layer(h)\n",
        "        return mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, input_dim, hidden_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dims[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[1], hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self, sigma=0.05):\n",
        "        for layer in self.model:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
        "                nn.init.constant_(layer.bias, 0.0)\n",
        "\n",
        "    def forward(self, z):\n",
        "        x_recon = self.model(z)\n",
        "        return x_recon.view(-1, 1, 28, 28)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dims):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[1], 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self, sigma=0.05):\n",
        "        for layer in self.model:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
        "                nn.init.constant_(layer.bias, 0.0)\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "def reparameterize(mu, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps * std\n",
        "\n",
        "class GANAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, latent_dim, l2_lambda=1e-3):\n",
        "        super(GANAE, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, hidden_dims, latent_dim)\n",
        "        self.decoder = Decoder(latent_dim, input_dim, hidden_dims)\n",
        "        self.discriminator = Discriminator(latent_dim, hidden_dims)\n",
        "        self.l2_lambda = l2_lambda\n",
        "\n",
        "    def compute_l2_penalty(self):\n",
        "        l2_penalty = 0\n",
        "        for param in self.decoder.parameters():\n",
        "            if param.requires_grad:\n",
        "                l2_penalty += torch.sum(param**2)\n",
        "        return self.l2_lambda * l2_penalty\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = reparameterize(mu, logvar)\n",
        "        x_recon = self.decoder(z)\n",
        "        real_or_fake = torch.sigmoid(self.discriminator(z))\n",
        "        return x_recon, real_or_fake, mu, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pHi74ASKnJC9"
      },
      "outputs": [],
      "source": [
        "# --- Loss Functions ---\n",
        "def bce_loss(pred, target):\n",
        "    return F.binary_cross_entropy(pred, target,reduction=\"sum\")\n",
        "\n",
        "def gan_ae_loss(recon_x, x, real_or_fake, real_label=1, fake_label=0):\n",
        "    # Reconstruction loss\n",
        "    recon_loss =bce_loss(recon_x, x)\n",
        "\n",
        "    # Discriminator loss (binary cross entropy)\n",
        "    d_loss_real = bce_loss(real_or_fake, torch.full_like(real_or_fake, real_label))\n",
        "    d_loss_fake = bce_loss(real_or_fake, torch.full_like(real_or_fake, fake_label))\n",
        "\n",
        "    return recon_loss + d_loss_real + d_loss_fake\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyF58LZ6nJC-",
        "outputId": "57ae7717-001d-4f1f-f3de-e5f4a307b2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/70]\n",
            "    Reconstruction Loss: 236.9476\n",
            "    KL Loss: 7.2343\n",
            "Epoch [2/70]\n",
            "    Reconstruction Loss: 155.4494\n",
            "    KL Loss: 11.5451\n",
            "Epoch [3/70]\n",
            "    Reconstruction Loss: 133.3719\n",
            "    KL Loss: 15.8849\n",
            "Epoch [4/70]\n",
            "    Reconstruction Loss: 120.9176\n",
            "    KL Loss: 18.5318\n",
            "Epoch [5/70]\n",
            "    Reconstruction Loss: 112.0258\n",
            "    KL Loss: 20.3965\n",
            "Epoch [6/70]\n",
            "    Reconstruction Loss: 104.4165\n",
            "    KL Loss: 21.8173\n",
            "Epoch [7/70]\n",
            "    Reconstruction Loss: 98.6005\n",
            "    KL Loss: 22.7700\n",
            "Epoch [8/70]\n",
            "    Reconstruction Loss: 94.1075\n",
            "    KL Loss: 23.4457\n",
            "Epoch [9/70]\n",
            "    Reconstruction Loss: 90.2136\n",
            "    KL Loss: 24.0164\n",
            "Epoch [10/70]\n",
            "    Reconstruction Loss: 86.8194\n",
            "    KL Loss: 24.4989\n",
            "Epoch [11/70]\n",
            "    Reconstruction Loss: 83.7665\n",
            "    KL Loss: 24.9587\n",
            "Epoch [12/70]\n",
            "    Reconstruction Loss: 81.0415\n",
            "    KL Loss: 25.4325\n",
            "Epoch [13/70]\n",
            "    Reconstruction Loss: 78.6642\n",
            "    KL Loss: 25.8932\n",
            "Epoch [14/70]\n",
            "    Reconstruction Loss: 76.6772\n",
            "    KL Loss: 26.2744\n",
            "Epoch [15/70]\n",
            "    Reconstruction Loss: 74.9225\n",
            "    KL Loss: 26.5631\n",
            "Epoch [16/70]\n",
            "    Reconstruction Loss: 73.2997\n",
            "    KL Loss: 26.8495\n",
            "Epoch [17/70]\n",
            "    Reconstruction Loss: 71.9338\n",
            "    KL Loss: 27.1011\n",
            "Epoch [18/70]\n",
            "    Reconstruction Loss: 70.6612\n",
            "    KL Loss: 27.3096\n",
            "Epoch [19/70]\n",
            "    Reconstruction Loss: 69.5332\n",
            "    KL Loss: 27.5095\n",
            "Epoch [20/70]\n",
            "    Reconstruction Loss: 68.4781\n",
            "    KL Loss: 27.6620\n",
            "Epoch [21/70]\n",
            "    Reconstruction Loss: 67.5283\n",
            "    KL Loss: 27.8336\n",
            "Epoch [22/70]\n",
            "    Reconstruction Loss: 66.6382\n",
            "    KL Loss: 27.9869\n",
            "Epoch [23/70]\n",
            "    Reconstruction Loss: 65.8145\n",
            "    KL Loss: 28.1459\n",
            "Epoch [24/70]\n",
            "    Reconstruction Loss: 65.0646\n",
            "    KL Loss: 28.2881\n",
            "Epoch [25/70]\n",
            "    Reconstruction Loss: 64.3509\n",
            "    KL Loss: 28.4118\n",
            "Epoch [26/70]\n",
            "    Reconstruction Loss: 63.7575\n",
            "    KL Loss: 28.5147\n",
            "Epoch [27/70]\n",
            "    Reconstruction Loss: 63.0824\n",
            "    KL Loss: 28.6192\n",
            "Epoch [28/70]\n",
            "    Reconstruction Loss: 62.5604\n",
            "    KL Loss: 28.7715\n",
            "Epoch [29/70]\n",
            "    Reconstruction Loss: 62.0340\n",
            "    KL Loss: 28.7983\n",
            "Epoch [30/70]\n",
            "    Reconstruction Loss: 61.5168\n",
            "    KL Loss: 28.9201\n",
            "Epoch [31/70]\n",
            "    Reconstruction Loss: 61.0329\n",
            "    KL Loss: 28.9856\n",
            "Epoch [32/70]\n",
            "    Reconstruction Loss: 60.5943\n",
            "    KL Loss: 29.0913\n",
            "Epoch [33/70]\n",
            "    Reconstruction Loss: 60.1157\n",
            "    KL Loss: 29.1629\n",
            "Epoch [34/70]\n",
            "    Reconstruction Loss: 59.7250\n",
            "    KL Loss: 29.2190\n",
            "Epoch [35/70]\n",
            "    Reconstruction Loss: 59.3136\n",
            "    KL Loss: 29.3579\n",
            "Epoch [36/70]\n",
            "    Reconstruction Loss: 58.9184\n",
            "    KL Loss: 29.3890\n",
            "Epoch [37/70]\n",
            "    Reconstruction Loss: 58.5368\n",
            "    KL Loss: 29.4674\n",
            "Epoch [38/70]\n",
            "    Reconstruction Loss: 58.2330\n",
            "    KL Loss: 29.5079\n",
            "Epoch [39/70]\n",
            "    Reconstruction Loss: 57.8613\n",
            "    KL Loss: 29.5880\n",
            "Epoch [40/70]\n",
            "    Reconstruction Loss: 57.5648\n",
            "    KL Loss: 29.6536\n",
            "Epoch [41/70]\n",
            "    Reconstruction Loss: 57.2430\n",
            "    KL Loss: 29.7071\n",
            "Epoch [42/70]\n",
            "    Reconstruction Loss: 56.9488\n",
            "    KL Loss: 29.7806\n",
            "Epoch [43/70]\n",
            "    Reconstruction Loss: 56.6747\n",
            "    KL Loss: 29.8402\n",
            "Epoch [44/70]\n",
            "    Reconstruction Loss: 56.4348\n",
            "    KL Loss: 29.8801\n",
            "Epoch [45/70]\n",
            "    Reconstruction Loss: 56.1908\n",
            "    KL Loss: 29.9204\n",
            "Epoch [46/70]\n",
            "    Reconstruction Loss: 55.9353\n",
            "    KL Loss: 29.9670\n",
            "Epoch [47/70]\n",
            "    Reconstruction Loss: 55.6995\n",
            "    KL Loss: 30.0011\n",
            "Epoch [48/70]\n",
            "    Reconstruction Loss: 55.4576\n",
            "    KL Loss: 30.0532\n",
            "Epoch [49/70]\n",
            "    Reconstruction Loss: 55.2370\n",
            "    KL Loss: 30.1061\n",
            "Epoch [50/70]\n",
            "    Reconstruction Loss: 55.0529\n",
            "    KL Loss: 30.0956\n",
            "Epoch [51/70]\n",
            "    Reconstruction Loss: 54.8363\n",
            "    KL Loss: 30.1652\n",
            "Epoch [52/70]\n",
            "    Reconstruction Loss: 54.6504\n",
            "    KL Loss: 30.2227\n",
            "Epoch [53/70]\n",
            "    Reconstruction Loss: 54.4488\n",
            "    KL Loss: 30.2911\n",
            "Epoch [54/70]\n",
            "    Reconstruction Loss: 54.2110\n",
            "    KL Loss: 30.3089\n",
            "Epoch [55/70]\n",
            "    Reconstruction Loss: 54.0751\n",
            "    KL Loss: 30.3434\n",
            "Epoch [56/70]\n",
            "    Reconstruction Loss: 53.9040\n",
            "    KL Loss: 30.3429\n",
            "Epoch [57/70]\n",
            "    Reconstruction Loss: 53.7644\n",
            "    KL Loss: 30.4190\n",
            "Epoch [58/70]\n",
            "    Reconstruction Loss: 53.5941\n",
            "    KL Loss: 30.4362\n",
            "Epoch [59/70]\n",
            "    Reconstruction Loss: 53.3885\n",
            "    KL Loss: 30.4752\n",
            "Epoch [60/70]\n",
            "    Reconstruction Loss: 53.2414\n",
            "    KL Loss: 30.4955\n",
            "Epoch [61/70]\n",
            "    Reconstruction Loss: 53.0940\n",
            "    KL Loss: 30.5486\n",
            "Epoch [62/70]\n",
            "    Reconstruction Loss: 52.9381\n",
            "    KL Loss: 30.5582\n",
            "Epoch [63/70]\n",
            "    Reconstruction Loss: 52.7776\n",
            "    KL Loss: 30.5735\n",
            "Epoch [64/70]\n",
            "    Reconstruction Loss: 52.6319\n",
            "    KL Loss: 30.6176\n",
            "Epoch [65/70]\n",
            "    Reconstruction Loss: 52.4867\n",
            "    KL Loss: 30.6573\n"
          ]
        }
      ],
      "source": [
        "# --- Training Loop ---\n",
        "\n",
        "# Initialize model with proper parameters\n",
        "input_dim = 784  # 28x28 for MNIST\n",
        "hidden_dims = [360, 360]  # Example dimensions\n",
        "latent_dim = 40  # Example latent dimension\n",
        "ganae = GANAE(input_dim=input_dim, hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
        "\n",
        "# Separate optimizers for generator (encoder+decoder) and discriminator\n",
        "gen_optimizer = torch.optim.Adam(list(ganae.encoder.parameters()) +\n",
        "                               list(ganae.decoder.parameters()), lr=0.0002)\n",
        "disc_optimizer = torch.optim.Adam(ganae.discriminator.parameters(), lr=0.00002)\n",
        "\n",
        "# Loss functions\n",
        "reconstruction_loss = nn.BCELoss(reduction='sum')\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "\n",
        "def rescale_gradients(model, max_norm=5.0):\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
        "\n",
        "\n",
        "\n",
        "def compute_loss(x_recon, x, real_or_fake, mu, logvar):\n",
        "    # Flatten the input and reconstruction for BCE loss\n",
        "    x_recon_flat = x_recon.view(-1, input_dim)\n",
        "    x_flat = x.view(-1, input_dim)\n",
        "\n",
        "    # Reconstruction loss\n",
        "    recon_loss = reconstruction_loss(x_recon_flat, x_flat)\n",
        "\n",
        "    # KL divergence\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # Adversarial loss\n",
        "    real_labels = torch.ones(real_or_fake.size()).to(x.device)\n",
        "    fake_labels = torch.zeros(real_or_fake.size()).to(x.device)\n",
        "\n",
        "    # Generator tries to fool discriminator\n",
        "    gen_loss = adversarial_loss(real_or_fake, real_labels)\n",
        "\n",
        "    # Discriminator loss\n",
        "    disc_loss = adversarial_loss(real_or_fake, fake_labels)\n",
        "\n",
        "\n",
        "    return recon_loss, kl_loss, gen_loss, disc_loss\n",
        "\n",
        "# Training loop\n",
        "n_epochs = opt.n_epochs\n",
        "for epoch in range(n_epochs):\n",
        "    total_recon_loss = 0\n",
        "    total_kl_loss = 0\n",
        "    total_gen_loss = 0\n",
        "    total_disc_loss = 0\n",
        "\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        batch_size = data.size(0)\n",
        "        data = data.to('cpu')\n",
        "        data = (data > 0.5).float()\n",
        "\n",
        "        # Train generator (encoder + decoder)\n",
        "        gen_optimizer.zero_grad()\n",
        "        x_recon, real_or_fake, mu, logvar = ganae(data)\n",
        "        recon_loss, kl_loss, gen_loss, _ = compute_loss(x_recon, data, real_or_fake, mu, logvar)\n",
        "\n",
        "        # Add L2 regularization\n",
        "        l2_penalty = ganae.compute_l2_penalty()\n",
        "\n",
        "        # Total generator loss\n",
        "        g_loss = recon_loss + kl_loss + gen_loss + l2_penalty\n",
        "        # Reduce KL impact (scale it down)\n",
        "        # g_loss = recon_loss + 0.01 * kl_loss + gen_loss + l2_penalty\n",
        "\n",
        "        g_loss.backward(retain_graph=True)\n",
        "        rescale_gradients(ganae)\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        # Train discriminator\n",
        "        # disc_optimizer.zero_grad()\n",
        "        # _, real_or_fake, _, _ = ganae(data)\n",
        "        # _, _, _, disc_loss = compute_loss(x_recon, data, real_or_fake, mu, logvar)\n",
        "        # disc_loss.backward()\n",
        "        # rescale_gradients(ganae)\n",
        "        # disc_optimizer.step()\n",
        "        n_critic = 5  # Number of times to train discriminator per generator step\n",
        "\n",
        "        for _ in range(n_critic):  # Train discriminator multiple times\n",
        "            disc_optimizer.zero_grad()\n",
        "            _, real_or_fake, _, _ = ganae(data)\n",
        "            _, _, _, disc_loss = compute_loss(x_recon, data, real_or_fake, mu, logvar)\n",
        "            disc_loss.backward()\n",
        "            rescale_gradients(ganae)\n",
        "            disc_optimizer.step()\n",
        "\n",
        "\n",
        "        # Record losses\n",
        "        total_recon_loss += recon_loss.item()\n",
        "        total_kl_loss += kl_loss.item()\n",
        "        total_gen_loss += gen_loss.item()\n",
        "        total_disc_loss += disc_loss.item()\n",
        "\n",
        "    # Average losses\n",
        "    avg_recon_loss = total_recon_loss / len(train_loader.dataset)\n",
        "    avg_kl_loss = total_kl_loss / len(train_loader.dataset)\n",
        "    avg_gen_loss = total_gen_loss / len(train_loader.dataset)\n",
        "    avg_disc_loss = total_disc_loss / len(train_loader.dataset)\n",
        "\n",
        "    print(f\"\"\"Epoch [{epoch+1}/{n_epochs}]\n",
        "    Reconstruction Loss: {avg_recon_loss:.4f}\n",
        "    KL Loss: {avg_kl_loss:.4f}\"\"\")\n",
        "    # print(f\"Generator Loss: {avg_gen_loss:.4f}\")\n",
        "    # print(f\"Discriminator Loss: {avg_disc_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2qjjbmEnJDB",
        "outputId": "5484f672-c084-47e6-d779-6d88914cf8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BCE: 80.3978, MSE: 9.6159\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(80.397849609375, 9.615925988769531)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate error\n",
        "def calculate_error(model, loader):\n",
        "    model.eval()\n",
        "    total_bce = 0.0\n",
        "    total_mse = 0.0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in loader:\n",
        "            data = data.view(data.size(0), -1)\n",
        "            model_output = model(data)  # Capture all outputs\n",
        "\n",
        "            recon_data = model_output[0] if isinstance(model_output, tuple) else model_output\n",
        "\n",
        "            #recon_data, _ = model(data)\n",
        "            recon_data = recon_data.view(data.size(0), -1)\n",
        "            bce = F.binary_cross_entropy(recon_data, data, reduction='sum')\n",
        "            total_bce += bce.item()\n",
        "            mse = F.mse_loss(recon_data, data, reduction='sum')\n",
        "            total_mse += mse.item()\n",
        "            total_samples += data.size(0)\n",
        "\n",
        "    avg_bce = total_bce / total_samples\n",
        "    avg_mse = total_mse / total_samples\n",
        "    print(f\"BCE: {avg_bce:.4f}, MSE: {avg_mse:.4f}\")\n",
        "    return avg_bce, avg_mse\n",
        "\n",
        "calculate_error(ganae, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8J-nuGasnJDD"
      },
      "outputs": [],
      "source": [
        "def evaluate_classification_gan_ae(model, train_loader, test_loader):\n",
        "    model.eval()\n",
        "    train_latents, train_labels = [], []\n",
        "    test_latents, test_labels = [], []\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Extract latent representations from training data\n",
        "    with torch.no_grad():\n",
        "        for data, label in train_loader:\n",
        "            data = (data > 0.5).float().view(-1, 784).to(device)\n",
        "            mu, logvar = model.encoder(data)\n",
        "            z = reparameterize(mu, logvar)\n",
        "            train_latents.append(z.cpu().numpy())\n",
        "            train_labels.append(label.cpu().numpy())\n",
        "\n",
        "    # Extract latent representations from test data\n",
        "    with torch.no_grad():\n",
        "        for data, label in test_loader:\n",
        "            data = (data > 0.5).float().view(-1, 784).to(device)\n",
        "            mu, logvar = model.encoder(data)\n",
        "            z = reparameterize(mu, logvar)\n",
        "            test_latents.append(z.cpu().numpy())\n",
        "            test_labels.append(label.cpu().numpy())\n",
        "\n",
        "    # Stack latent representations and labels\n",
        "    X_train = np.vstack(train_latents)\n",
        "    y_train = np.hstack(train_labels)\n",
        "    X_test = np.vstack(test_latents)\n",
        "    y_test = np.hstack(test_labels)\n",
        "\n",
        "    # Train logistic regression on training latents\n",
        "    classifier = LogisticRegression(max_iter=1000)\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on test latents\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    error_percentage = 100 * (1 - accuracy_score(y_test, y_pred))\n",
        "\n",
        "    print(f\"Classification Error: {error_percentage:.2f}%\")\n",
        "    return error_percentage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfI8GKuCnJDE",
        "outputId": "b5128843-28a6-4501-fa98-656071c26888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Error: 14.03%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "14.029999999999998"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_classification_gan_ae(ganae,train_loader,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eDB6BTKsnJDF"
      },
      "outputs": [],
      "source": [
        "def evaluate_masked_mse(model, loader):\n",
        "    \"\"\"\n",
        "    Evaluate the Masked Mean Squared Error (M-MSE) for the GAN-AE model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained GAN-AE model.\n",
        "    - loader: DataLoader with test data.\n",
        "\n",
        "    Returns:\n",
        "    - avg_mse: Average MSE over masked regions, normalized by masked elements.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_mse = 0.0\n",
        "    total_masked_elements = 0\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, _ in loader:\n",
        "            data = (data > 0.5).float().view(-1, 784).to(device)  # Binarize and flatten\n",
        "\n",
        "            # Create mask: mask first half of the image (392/784 pixels)\n",
        "            mask = torch.ones_like(data, dtype=torch.bool)\n",
        "            mask[:, :392] = 0  # Mask left half\n",
        "\n",
        "            # Apply mask to input\n",
        "            masked_data = data * mask.float()\n",
        "\n",
        "            # Encode and sample from latent space\n",
        "            mu, logvar = model.encoder(masked_data)\n",
        "            z = reparameterize(mu, logvar)\n",
        "\n",
        "            # Decode to reconstruct\n",
        "            reconstructed = model.decoder(z).view(-1, 784)\n",
        "\n",
        "            # Compute MSE on masked region only\n",
        "            masked_error = F.mse_loss(reconstructed[~mask], data[~mask], reduction='sum')\n",
        "            total_mse += masked_error.item()\n",
        "            total_masked_elements += (~mask).sum().item()\n",
        "\n",
        "    # Normalize by total number of masked elements\n",
        "    avg_mse = total_mse / total_masked_elements\n",
        "    print(f\"Average Masked MSE: {avg_mse:.4f}\")\n",
        "    return avg_mse\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnryqWhsnJDG",
        "outputId": "b911ea07-e8e6-4335-d954-12cd32f7d2df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Masked MSE: 0.1125\n",
            "0.1125103900520169\n"
          ]
        }
      ],
      "source": [
        "avg_mse = evaluate_masked_mse(ganae, test_loader)\n",
        "print(avg_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOpJPvx54ipJ",
        "outputId": "a4374025-01c3-4f8e-b904-c1c6d00f884b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated log p(x): -207.98837602615356\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def monte_carlo_log_px(model, data_loader, num_samples=1000, device='cpu'):\n",
        "    model.eval()\n",
        "    total_log_px = 0\n",
        "    num_images = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            x_real = batch[0].to(device)\n",
        "            batch_size = x_real.size(0)\n",
        "\n",
        "            z_samples = torch.randn(num_samples, latent_dim).to(device)\n",
        "\n",
        "            x_recon = model.decoder(z_samples)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                log_px = compute_log_px(x_real[i], x_recon)\n",
        "                total_log_px += log_px.item()\n",
        "                num_images += 1\n",
        "\n",
        "            if num_images >= num_samples:\n",
        "                break\n",
        "\n",
        "    average_log_px = total_log_px / num_images\n",
        "    return average_log_px\n",
        "\n",
        "def compute_log_px(x_real, x_recon):\n",
        "    x_real_expanded = x_real.unsqueeze(0).expand(x_recon.size(0), -1, -1, -1)\n",
        "\n",
        "    log_px = -F.binary_cross_entropy(x_recon, x_real_expanded, reduction='none')\n",
        "    log_px = torch.logsumexp(log_px.sum(dim=[1,2,3]), dim=0) - torch.log(torch.tensor(x_recon.size(0)))\n",
        "    return log_px\n",
        "\n",
        "log_px_estimate = monte_carlo_log_px(ganae, test_loader, num_samples=1000, device='cpu')\n",
        "print(f\"Estimated log p(x): {log_px_estimate}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfCD1ZBrMSfg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
